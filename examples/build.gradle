/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */


String flinkVersion = '1.14.0'
String flinkMajorVersion = '1.14'
String scalaVersion = System.getProperty("scalaVersion") != null ? System.getProperty("scalaVersion") : System.getProperty("defaultScalaVersion")
project(":iceberg-examples") {
    apply plugin: 'scala'
    apply plugin: 'com.github.alisiikh.scalastyle'

    dependencies {
        compileOnly "org.scala-lang:scala-library:${scalaVersion}"

        implementation project(":iceberg-flink:iceberg-flink-${flinkMajorVersion}")

        implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')
        api project(':iceberg-api')
        implementation project(':iceberg-common')
        implementation project(':iceberg-core')
        api project(':iceberg-data')
        implementation project(':iceberg-orc')
        implementation project(':iceberg-parquet')
        implementation project(':iceberg-hive-metastore')

        implementation "org.apache.flink:flink-streaming-java_${scalaVersion}:${flinkVersion}"
        implementation "org.apache.flink:flink-streaming-java_${scalaVersion}:${flinkVersion}:tests"
        implementation "org.apache.flink:flink-table-api-java-bridge_${scalaVersion}:${flinkVersion}"
        implementation "org.apache.flink:flink-table-planner_${scalaVersion}:${flinkVersion}"
        implementation "org.apache.hadoop:hadoop-hdfs"
        implementation "org.apache.hadoop:hadoop-common"
        implementation("org.apache.hadoop:hadoop-minicluster") {
            exclude group: 'org.apache.avro', module: 'avro'
        }
        implementation "org.apache.flink:flink-core:${flinkVersion}"

        implementation("org.apache.parquet:parquet-avro") {
            exclude group: 'org.apache.avro', module: 'avro'
            // already shaded by Parquet
            exclude group: 'it.unimi.dsi'
            exclude group: 'org.codehaus.jackson'
        }

        compileOnly "org.apache.avro:avro"

        implementation("org.apache.orc:orc-core::nohive") {
            exclude group: 'org.apache.hadoop'
            exclude group: 'commons-lang'
            // These artifacts are shaded and included in the orc-core fat jar
            exclude group: 'com.google.protobuf', module: 'protobuf-java'
            exclude group: 'org.apache.hive', module: 'hive-storage-api'
        }

        implementation "org.apache.flink:flink-core:${flinkVersion}"
        implementation "org.apache.flink:flink-runtime:${flinkVersion}"
        implementation ("org.apache.flink:flink-test-utils-junit:${flinkVersion}") {
            exclude group: 'junit'
        }
        implementation("org.apache.flink:flink-test-utils_${scalaVersion}:${flinkVersion}") {
            exclude group: "org.apache.curator", module: 'curator-test'
            exclude group: 'junit'
        }

        testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')
        testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')
        testImplementation project(path: ':iceberg-data', configuration: 'testArtifacts')

        // By default, hive-exec is a fat/uber jar and it exports a guava library
        // that's really old. We use the core classifier to be able to override our guava
        // version. Luckily, hive-exec seems to work okay so far with this version of guava
        // See: https://github.com/apache/hive/blob/master/ql/pom.xml#L911 for more context.
    }
}
